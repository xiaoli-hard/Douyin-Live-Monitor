#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºçœŸå®æ•°æ®çš„åŠ¨æ€åŸºçº¿ç³»ç»Ÿæ ¸å¿ƒæ¨¡å—
æ”¯æŒ53ä¸ªæŒ‡æ ‡çš„æ™ºèƒ½è¯„ä¼°
"""

import pandas as pd
import numpy as np
import json
import sqlite3
import pickle
import os
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Any, Optional
import warnings
import re # Added for regex in real_time_diagnosis
import logging
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)

class RealDataDynamicBaseline:
    """åŸºäºçœŸå®æ•°æ®çš„åŠ¨æ€åŸºçº¿ç³»ç»Ÿ"""
    
    def __init__(self, data_dir: str = "./æ•°æ®å­˜å‚¨"):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        self.data_dir = data_dir
        self.state_dir = os.path.join(data_dir, "ç³»ç»ŸçŠ¶æ€_real_data")
        os.makedirs(self.state_dir, exist_ok=True)
        
        # ç³»ç»ŸçŠ¶æ€æ–‡ä»¶
        self.state_file = os.path.join(self.state_dir, "system_state.pkl")
        self.db_file = os.path.join(self.state_dir, "error_logs.db")
        
        # --- æ–°å¢: åˆ—åæ˜ å°„å­—å…¸ï¼Œç”¨äºå…¼å®¹ä¸åŒçš„å†å²æ•°æ®æºæ ¼å¼ ---
        self.column_mapping = {
            'æ—¶é—´æ®µ': 'å°æ—¶',
            'æ•´ä½“GPM': 'GPM',
            'å•†å“-æ›å…‰äººæ•°': 'å•†å“æ›å…‰äººæ•°',
            'å•†å“-ç‚¹å‡»äººæ•°': 'å•†å“ç‚¹å‡»äººæ•°',
            'å•†å“æ›å…‰-ç‚¹å‡»ç‡': 'å•†å“ç‚¹å‡»ç‡',
            'ç›´æ’­é—´æ›å…‰-è¿›å…¥ç‡': 'æ›å…‰è¿›å…¥ç‡',
            'å•†å“ç‚¹å‡»-è½¬åŒ–ç‡': 'ç‚¹å‡»è½¬åŒ–ç‡',
            'é€€è´§è®¢å•é‡‘é¢': 'é€€æ¬¾é‡‘é¢',
            'å¤§ç“¶GMV': 'å¤§ç“¶è£…è®¢å•æ•°',
            'ä¸‰ç“¶GMV': 'ä¸‰ç“¶è£…è®¢å•æ•°',
            'å¹³å‡åœ¨çº¿äººæ•°': 'å¹³å‡åœ¨çº¿',
            'ç›´æ’­é—´æ›å…‰é‡': 'ç›´æ’­é—´æ›å…‰æ¬¡æ•°',
            'å¹¿å‘ŠROI': 'å®é™…ROI',
            'å¹¿å‘ŠGMV': 'æ•´ä½“GSV',
            'åœç•™æ—¶é•¿': 'äººå‡è§‚çœ‹æ—¶é•¿',
            'ä¼˜æƒ åˆ¸': 'æ™ºèƒ½ä¼˜æƒ åŠµé‡‘é¢',
            'è§‚çœ‹-æˆäº¤ç‡': 'æ•´ä½“uvä»·å€¼',
            # ä¿®å¤æ˜ å°„å…³ç³» - ç§»é™¤é”™è¯¯çš„æ˜ å°„ï¼Œä¿æŒæ•°æ®å®Œæ•´æ€§
            'å†…å®¹äº’åŠ¨äººæ•°': 'ç›´æ’­é—´è¿›å…¥äººæ•°',
            'æ–°å¢ç²‰ä¸å›¢äººæ•°': 'æˆäº¤äººæ•°_1',
            'ç›´æ’­é—´è¯„è®ºæ•°': 'åœ¨çº¿å³°å€¼',
            'é€€è´§è®¢å•æ•°': 'æˆäº¤ä»¶æ•°',
            'æˆäº¤è®¢å•æˆæœ¬': 'å¼•æµæˆæœ¬'
            # ç§»é™¤é‡å¤æŒ‡æ ‡æ˜ å°„: 'ç›´æ’­é—´æ›å…‰äººæ•°.1' å’Œ 'æˆäº¤äººæ•°.1'
        }
        
        # æŒ‡æ ‡åˆ†ç±»é…ç½® (å·²æ›´æ–°ï¼ŒåŒ…å«æ‰€æœ‰56ä¸ªæŒ‡æ ‡)
        self.absolute_indicators = [
            'æ¶ˆè€—', 'æ•´ä½“GMV', 'æ™ºèƒ½ä¼˜æƒ åŠµé‡‘é¢', 'é€€æ¬¾é‡‘é¢', 'æ•´ä½“GSV', 'æˆäº¤äººæ•°', 
            'æˆäº¤ä»¶æ•°', 'ç›´æ’­é—´æ›å…‰æ¬¡æ•°', 'ç›´æ’­é—´æ›å…‰äººæ•°', 'ç›´æ’­é—´è¿›å…¥äººæ•°', 
            'ç›´æ’­é—´è§‚çœ‹æ¬¡æ•°', 'åœ¨çº¿å³°å€¼', 'å¹³å‡åœ¨çº¿', 'å¼•æµæˆæœ¬', 'è½¬åŒ–æˆæœ¬', 
            'æ•´ä½“uvä»·å€¼', 'GPM', 'äººå‡è§‚çœ‹æ—¶é•¿', 'è§‚çœ‹äººæ•°', 'å•†å“æ›å…‰äººæ•°', 
            'å•†å“ç‚¹å‡»äººæ•°', 'ç”»é¢-æ¶ˆè€—', 'ç”»é¢-gmv', 'ç”»é¢-æ›å…‰æ•°', 'ç”»é¢-ç‚¹å‡»æ•°', 
            'ç”»é¢-è½¬åŒ–æ•°', 'è§†é¢‘-æ¶ˆè€—', 'è§†é¢‘-gmv', 'è§†é¢‘-æ›å…‰æ•°', 'è§†é¢‘-ç‚¹å‡»æ•°', 
            'è§†é¢‘-è½¬åŒ–æ•°', 'è°ƒæ§æ¶ˆè€—', 'è°ƒæ§GMV', 'è°ƒæ§æˆäº¤è®¢å•æ•°'
        ]
        self.ratio_indicators = [
            'æ•´ä½“ROI', 'å®é™…ROI', 'å®¢å•ä»·', 'æ›å…‰è¿›å…¥ç‡', 'å•†å“-æ›å…‰ç‡', 
            'å•†å“ç‚¹å‡»ç‡', 'ç‚¹å‡»è½¬åŒ–ç‡', 'ç”»é¢-roi', 'ç”»é¢-æ¶ˆè€—å æ¯”', 
            'ç”»é¢-CTR', 'ç”»é¢-CVR', 'è§†é¢‘-roi', 'è§†é¢‘-æ¶ˆè€—å æ¯”', 
            'è§†é¢‘-CTR', 'è§†é¢‘-CVR', 'è°ƒæ§ROI', 'è°ƒæ§-æ¶ˆè€—å æ¯”'
        ]
        
        # ç³»ç»ŸçŠ¶æ€
        self.data_pool = []
        self.baseline_table = {}
        self.standard_progress_table = {}
        self.is_initialized = False
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_database()
        
        # å°è¯•åŠ è½½ç°æœ‰çŠ¶æ€
        self._load_state()
        
        print(f"ğŸ¯ åŠ¨æ€åŸºçº¿ç³»ç»Ÿå·²åˆå§‹åŒ–")
        print(f"ğŸ“Š æ”¯æŒæŒ‡æ ‡: ç»å¯¹æ•°å€¼å‹{len(self.absolute_indicators)}ä¸ª, æ¯”ç‡å‹{len(self.ratio_indicators)}ä¸ª")
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        try:
            conn = sqlite3.connect(self.db_file)
            cursor = conn.cursor()
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS error_logs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT,
                    level TEXT,
                    message TEXT,
                    details TEXT
                )
            """)
            conn.commit()
            conn.close()
        except Exception as e:
            print(f"âš ï¸ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _log_error(self, level: str, message: str, details: str = ""):
        """è®°å½•é”™è¯¯æ—¥å¿—"""
        try:
            conn = sqlite3.connect(self.db_file)
            cursor = conn.cursor()
            cursor.execute("""
                INSERT INTO error_logs (timestamp, level, message, details)
                VALUES (?, ?, ?, ?)
            """, (datetime.now().isoformat(), level, message, details))
            conn.commit()
            conn.close()
        except:
            pass
    
    def _save_state(self):
        """ä¿å­˜ç³»ç»ŸçŠ¶æ€"""
        try:
            state = {
                'data_pool': self.data_pool,
                'baseline_table': self.baseline_table,
                'standard_progress_table': self.standard_progress_table,
                'is_initialized': self.is_initialized,
                'last_update': datetime.now().isoformat()
            }
            with open(self.state_file, 'wb') as f:
                pickle.dump(state, f)
        except Exception as e:
            self._log_error("ERROR", f"ä¿å­˜çŠ¶æ€å¤±è´¥", str(e))
    
    def _load_state(self):
        """åŠ è½½ç³»ç»ŸçŠ¶æ€"""
        try:
            if os.path.exists(self.state_file):
                with open(self.state_file, 'rb') as f:
                    state = pickle.load(f)
                self.data_pool = state.get('data_pool', [])
                self.baseline_table = state.get('baseline_table', {})
                self.standard_progress_table = state.get('standard_progress_table', {})
                self.is_initialized = state.get('is_initialized', False)
                print(f"âœ… ç³»ç»ŸçŠ¶æ€å·²åŠ è½½ï¼Œæ•°æ®æ± åŒ…å«{len(self.data_pool)}æ¡è®°å½•")
        except Exception as e:
            self._log_error("WARNING", f"åŠ è½½çŠ¶æ€å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®", str(e))
    
    def initialize_system(self, historical_data_path: str) -> bool:
        """
        ä½¿ç”¨å†å²æ•°æ®åˆå§‹åŒ–ç³»ç»Ÿ
        
        Args:
            historical_data_path: å†å²æ•°æ®æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
        """
        try:
            print(f"ğŸš€ å¼€å§‹åˆå§‹åŒ–ç³»ç»Ÿ...")
            
            # è¯»å–å†å²æ•°æ®ï¼Œå¢åŠ  on_bad_lines='skip' æ¥è·³è¿‡æ ¼å¼é”™è¯¯çš„è¡Œ
            if historical_data_path.endswith('.csv'):
                df = pd.read_csv(historical_data_path, on_bad_lines='skip')
            else:
                df = pd.read_excel(historical_data_path)
            
            print(f"ğŸ“Š å†å²æ•°æ®: {len(df)}è¡Œ {len(df.columns)}åˆ— (å·²è·³è¿‡é”™è¯¯è¡Œ)")
            
            # æ•°æ®é¢„å¤„ç†
            df = self._preprocess_data(df)
            
            if len(df) == 0:
                print("âŒ æœ‰æ•ˆæ•°æ®ä¸ºç©ºï¼Œæ— æ³•åˆå§‹åŒ–")
                return False
            
            # å°†å†å²æ•°æ®æ·»åŠ åˆ°æ•°æ®æ± 
            self.data_pool = []
            for _, row in df.iterrows():
                self.data_pool.append(row.to_dict())
            
            # è®¡ç®—åŸºçº¿å’Œæ ‡å‡†è¿›åº¦è¡¨
            self._calculate_baseline()
            self._calculate_standard_progress_table()
            
            self.is_initialized = True
            self._save_state()
            
            print(f"âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
            print(f"ğŸ“ˆ åŸºçº¿è¦†ç›–: {len(self.baseline_table)}ä¸ªæ—¶æ®µ")
            print(f"ğŸ“Š æ ‡å‡†è¿›åº¦è¡¨: {len(self.standard_progress_table)}ä¸ªæ—¶æ®µ")
            
            return True
            
        except Exception as e:
            error_msg = f"åˆå§‹åŒ–å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self._log_error("ERROR", error_msg, str(e))
            return False
    
    def _preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ•°æ®é¢„å¤„ç† - v3 (é‡æ„ç‰ˆï¼Œå¢åŠ åˆ—åæ˜ å°„å’Œæ›´å¼ºçš„æ¸…æ´—èƒ½åŠ›)
        """
        try:
            print("ğŸ”§ å¼€å§‹æ‰§è¡Œæ–°ç‰ˆæ•°æ®é¢„å¤„ç†...")
            original_rows = len(df)
            
            # --- æ­¥éª¤ 1: ç»Ÿä¸€åˆ—å ---
            df.rename(columns=self.column_mapping, inplace=True)
            renamed_cols = [k for k in self.column_mapping.keys() if k in df.columns]
            if renamed_cols:
                print(f"   - åˆ—åé‡å‘½å: {', '.join(renamed_cols)}")

            # --- æ­¥éª¤ 2: æ¸…æ´—æ— æ•ˆå­—ç¬¦å’Œæ ¼å¼åŒ– ---
            # æ›¿æ¢ `-` ä¸º NaN
            df.replace('-', np.nan, inplace=True)

            # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
            required_fields = ["æ—¥æœŸ", "å°æ—¶", "ä¸»æ’­"]
            for field in required_fields:
                if field not in df.columns:
                    print(f"âš ï¸ é¢„å¤„ç†å¤±è´¥: ç¼ºå°‘å…³é”®åˆ— '{field}'")
                    return pd.DataFrame()

            # --- æ­¥éª¤ 3: å¤„ç†æ—¶é—´å­—æ®µ ---
            df["å°æ—¶"] = df["å°æ—¶"].astype(str).str.extract(r'(\d+)', expand=False)
            df["å°æ—¶"] = pd.to_numeric(df["å°æ—¶"], errors='coerce')
            df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"], errors='coerce')
            
            # ä¸¢å¼ƒæ²¡æœ‰æœ‰æ•ˆæ—¶é—´çš„è¡Œ
            df.dropna(subset=["æ—¥æœŸ", "å°æ—¶"], inplace=True)
            df["æ˜ŸæœŸå‡ "] = df["æ—¥æœŸ"].dt.dayofweek
            
            # --- æ­¥éª¤ 4: å¼ºåˆ¶è½¬æ¢æ‰€æœ‰æŒ‡æ ‡ä¸ºæ•°å€¼ï¼Œå¹¶ç§»é™¤è„æ•°æ® ---
            all_indicators = self.absolute_indicators + self.ratio_indicators
            for indicator in all_indicators:
                if indicator in df.columns:
                    df[indicator] = pd.to_numeric(df[indicator], errors='coerce')
            
            # ç§»é™¤å…³é”®è´¢åŠ¡æŒ‡æ ‡ä¸ºç©ºæˆ–0çš„è¡Œ
            key_financial_metrics = ['æ¶ˆè€—', 'æ•´ä½“GMV']
            df.dropna(subset=key_financial_metrics, inplace=True)
            
            # ä½¿ç”¨å‘é‡åŒ–æ“ä½œç§»é™¤0å€¼è¡Œ
            if not df.empty:
                conditions = [df[metric] != 0 for metric in key_financial_metrics if metric in df.columns]
                if conditions:
                    final_mask = np.logical_and.reduce(conditions)
                    df = df[final_mask]  # type: ignore

            cleaned_rows = len(df)
            print(f"ğŸ§¹ æ•°æ®æ¸…æ´—å®Œæˆ: å…±å¤„ç†{original_rows}è¡Œ, ç§»é™¤{original_rows - cleaned_rows}è¡Œæ— æ•ˆæ•°æ®ã€‚")
            print(f"ğŸ“Š é¢„å¤„ç†åæœ‰æ•ˆæ•°æ®: {cleaned_rows}è¡Œ")
            
            return df
            
        except Exception as e:
            self._log_error("ERROR", f"æ•°æ®é¢„å¤„ç†å¤±è´¥", str(e))
            return pd.DataFrame()
    
    def _calculate_baseline(self):
        """è®¡ç®—ä¼ ç»ŸåŸºçº¿è¡¨"""
        try:
            print(f"ğŸ“Š è®¡ç®—ä¼ ç»ŸåŸºçº¿è¡¨...")
            
            df = pd.DataFrame(self.data_pool)
            self.baseline_table = {}
            
            # ä¸ºæ¯ä¸ªæ˜ŸæœŸå‡ -å°æ—¶ç»„åˆè®¡ç®—åŸºçº¿
            for day in range(7):  # 0-6 å¯¹åº”å‘¨ä¸€åˆ°å‘¨æ—¥
                for hour in range(24):  # 0-23 å°æ—¶
                    key = f"{day}_{hour}"
                    
                    # ç­›é€‰è¯¥æ—¶æ®µçš„æ•°æ®
                    mask = (df["æ˜ŸæœŸå‡ "] == day) & (df["å°æ—¶"] == hour)
                    subset = df[mask]
                    
                    if len(subset) > 0:
                        baseline_values = {}
                        
                        # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡çš„å¹³å‡å€¼
                        all_indicators = self.absolute_indicators + self.ratio_indicators
                        for indicator in all_indicators:
                            if indicator in subset.columns:
                                # Linter-friendly way to calculate mean, avoiding chain calls
                                numeric_series = pd.to_numeric(subset[indicator], errors='coerce')
                                valid_series = numeric_series.dropna() # type: ignore
                                if not valid_series.empty: # type: ignore
                                    baseline_values[indicator] = valid_series.mean() # type: ignore
                        
                        if baseline_values:
                            self.baseline_table[key] = baseline_values
            
            print(f"âœ… åŸºçº¿è¡¨è®¡ç®—å®Œæˆï¼Œè¦†ç›–{len(self.baseline_table)}ä¸ªæ—¶æ®µ")
            
        except Exception as e:
            error_msg = f"åŸºçº¿è®¡ç®—å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self._log_error("ERROR", error_msg, str(e))
    
    def _calculate_standard_progress_table(self):
        """è®¡ç®—æ ‡å‡†è¿›åº¦è¡¨ï¼ˆä»…é’ˆå¯¹ç»å¯¹æ•°å€¼å‹æŒ‡æ ‡ï¼‰"""
        try:
            print(f"ğŸ“ˆ è®¡ç®—æ ‡å‡†è¿›åº¦è¡¨...")
            
            df = pd.DataFrame(self.data_pool)
            self.standard_progress_table = {}
            
            # æŒ‰æ—¥æœŸåˆ†ç»„ï¼Œè®¡ç®—æ¯å¤©çš„ç´¯ç§¯è¿›åº¦
            daily_progress = {}
            
            for date, day_df in df.groupby("æ—¥æœŸ"):
                day_df = day_df.sort_values("å°æ—¶")
                daily_totals = {}
                
                # è®¡ç®—æ¯å¤©å„æŒ‡æ ‡çš„æ€»å€¼
                for indicator in self.absolute_indicators:
                    if indicator in day_df.columns:
                        values = pd.to_numeric(day_df[indicator], errors='coerce')
                        daily_totals[indicator] = values.sum() # type: ignore
                
                # è®¡ç®—ç´¯ç§¯è¿›åº¦
                for _, row in day_df.iterrows():
                    hour = int(row["å°æ—¶"])
                    day_of_week = int(row["æ˜ŸæœŸå‡ "])
                    
                    key = f"{day_of_week}_{hour}"
                    
                    if key not in daily_progress:
                        daily_progress[key] = {indicator: [] for indicator in self.absolute_indicators}
                    
                    # è®¡ç®—åˆ°å½“å‰å°æ—¶çš„ç´¯ç§¯å€¼
                    for indicator in self.absolute_indicators:
                        if indicator in day_df.columns:
                            mask = day_df["å°æ—¶"] <= hour
                            cumulative = pd.to_numeric(day_df[mask][indicator], errors='coerce').sum() # type: ignore
                            if daily_totals.get(indicator, 0) > 0:
                                progress = cumulative / daily_totals[indicator]
                                daily_progress[key][indicator].append(progress)
            
            # è®¡ç®—å¹³å‡è¿›åº¦
            for key, progress_data in daily_progress.items():
                self.standard_progress_table[key] = {}
                for indicator, progress_list in progress_data.items():
                    if progress_list:
                        self.standard_progress_table[key][indicator] = np.mean(progress_list)
            
            print(f"âœ… æ ‡å‡†è¿›åº¦è¡¨è®¡ç®—å®Œæˆï¼Œè¦†ç›–{len(self.standard_progress_table)}ä¸ªæ—¶æ®µ")
            
        except Exception as e:
            error_msg = f"æ ‡å‡†è¿›åº¦è¡¨è®¡ç®—å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self._log_error("ERROR", error_msg, str(e))
    
    def real_time_diagnosis(self, query: Dict[str, Any]) -> Dict[str, Any]:
        """
        å®æ—¶è¯Šæ–­æ¥å£ - v5.1 ä¿®å¤ç‰ˆ (å¢åŠ å®æ—¶æ•°æ®é¢„å¤„ç†)
        
        Args:
            query: æŸ¥è¯¢æ•°æ®ï¼ŒåŒ…å«æ˜ŸæœŸå‡ ã€å°æ—¶å’Œå„é¡¹æŒ‡æ ‡å€¼
            
        Returns:
            Dict: è¯¦ç»†è¯Šæ–­ç»“æœ
        """
        # raise ValueError(">>> å¦‚æœæ‚¨çœ‹åˆ°è¿™æ¡ä¿¡æ¯ï¼Œè¯æ˜æˆ‘ä»¬æ‰¾å¯¹è·¯äº†ï¼<<<")
        try:
            if not self.is_initialized:
                return {"error": "ç³»ç»Ÿæœªåˆå§‹åŒ–"}

            # logger.info("--- [æ•°æ®ç»ˆç‚¹æ¢é’ˆ] æ”¶åˆ°æ•°æ®ï¼Œå¼€å§‹é€ä¸ªæ£€æŸ¥æŒ‡æ ‡å ---")
            # for k in query.keys():
            #     logger.info(f"    - ç»ˆç‚¹Key: '{k}'")
            # logger.info("--- [æ•°æ®ç»ˆç‚¹æ¢é’ˆ] æ£€æŸ¥å®Œæˆ ---")


            # --- å…³é”®ä¿®å¤ï¼šå¯¹å®æ—¶æŸ¥è¯¢æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œä½¿å…¶ä¸å†å²æ•°æ®æ ¼å¼ä¸€è‡´ ---
            try:
                if 'æ—¥æœŸ' in query and isinstance(query['æ—¥æœŸ'], str):
                    dt_object = pd.to_datetime(query['æ—¥æœŸ'])
                    # ä¿®æ­£ï¼šä½¿ç”¨dayofweekè€Œä¸æ˜¯è‡ªå®šä¹‰è®¡ç®—ï¼Œç¡®ä¿ä¸å†å²æ•°æ®ä¸€è‡´
                    query['æ˜ŸæœŸå‡ '] = dt_object.dayofweek # 0=å‘¨ä¸€, 6=å‘¨æ—¥
                    print(f"å®æ—¶æ•°æ®æ—¥æœŸ: {query['æ—¥æœŸ']}, è½¬æ¢ä¸ºæ˜ŸæœŸå‡ : {query['æ˜ŸæœŸå‡ ']}")
                
                if 'å°æ—¶' in query and isinstance(query['å°æ—¶'], str):
                    # ä» '09:00-10:00' è¿™ç§æ ¼å¼ä¸­æå–å¼€å§‹çš„å°æ—¶
                    match = re.match(r'(\d{2}):\d{2}-\d{2}:\d{2}', query['å°æ—¶'])
                    if match:
                        query['å°æ—¶'] = int(match.group(1))
                        print(f"å®æ—¶æ•°æ®å°æ—¶: {query['å°æ—¶']} (ä» {query.get('å°æ—¶', 'æœªçŸ¥')} æå–)")
            except Exception as e:
                self._log_error("WARNING", "å®æ—¶æŸ¥è¯¢æ•°æ®é¢„å¤„ç†å¤±è´¥", str(e))
                print(f"âš ï¸ å®æ—¶æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
                # å³ä½¿å¤±è´¥ï¼Œä¹Ÿç»§ç»­ä½¿ç”¨ .get çš„é»˜è®¤å€¼ï¼Œè€Œä¸æ˜¯ä¸­æ–­
            
            # è·å–æ—¶æ®µé”®
            day = query.get("æ˜ŸæœŸå‡ ", 0)
            hour = query.get("å°æ—¶", 0)
            key = f"{day}_{hour}"
            print(f"ç”Ÿæˆçš„é”®: {key} (æ˜ŸæœŸå‡ ={day}, å°æ—¶={hour})")
            
            # æ£€æŸ¥åŸºçº¿è¡¨ä¸­æ˜¯å¦å­˜åœ¨è¯¥é”®
            if key in self.baseline_table:
                print(f"åŸºçº¿è¡¨ä¸­å­˜åœ¨é”® {key}ï¼ŒåŒ…å« {len(self.baseline_table[key])} ä¸ªæŒ‡æ ‡")
            else:
                print(f"âš ï¸ åŸºçº¿è¡¨ä¸­ä¸å­˜åœ¨é”® {key}ï¼Œè¿™å¯èƒ½å¯¼è‡´è¯„ä¼°å¤±è´¥")
                # å°è¯•æŸ¥æ‰¾æœ€æ¥è¿‘çš„é”®
                for test_key in self.baseline_table.keys():
                    test_day, test_hour = test_key.split('_')
                    if int(test_day) == day:
                        print(f"  - æ‰¾åˆ°åŒä¸€å¤©çš„é”®: {test_key}")
            
            results = {}
            dynamic_details = {}
            
            # åˆ†åˆ«å¤„ç†ç»å¯¹æ•°å€¼å‹å’Œæ¯”ç‡å‹æŒ‡æ ‡
            dynamic_indicators = []
            traditional_indicators = []
            skipped_indicators = []
            
            # ç»Ÿè®¡è¾“å…¥æŒ‡æ ‡
            input_indicators = []
            for indicator, value in query.items():
                if indicator in ["æ˜ŸæœŸå‡ ", "å°æ—¶", "ä¸»æ’­", "åœºæ§", "æ—¥æœŸ", "åœºæ¬¡"]:
                    continue
                input_indicators.append(indicator)
            
            print(f"ğŸ“Š è¾“å…¥æŒ‡æ ‡æ€»æ•°: {len(input_indicators)}ä¸ª")
            print(f"ğŸ“‹ è¾“å…¥æŒ‡æ ‡åˆ—è¡¨: {input_indicators}")
            
            # å¤„ç†æ¯ä¸ªæŒ‡æ ‡
            for indicator, value in query.items():
                if indicator in ["æ˜ŸæœŸå‡ ", "å°æ—¶", "ä¸»æ’­", "åœºæ§", "æ—¥æœŸ", "åœºæ¬¡"]:
                    continue
                
                if value is None or value == "":
                    skipped_indicators.append(f"{indicator} (æ•°å€¼ä¸ºç©º)")
                    continue
                
                try:
                    value = float(value)
                except:
                    skipped_indicators.append(f"{indicator} (æ•°å€¼æ ¼å¼é”™è¯¯)")
                    continue
                
                # åº”ç”¨åˆ—åæ˜ å°„
                mapped_indicator = self.column_mapping.get(indicator, indicator)
                
                if mapped_indicator in self.absolute_indicators:
                    # ç»å¯¹æ•°å€¼å‹æŒ‡æ ‡ä½¿ç”¨åŠ¨æ€è¯„ä¼°
                    result = self._dynamic_evaluation(mapped_indicator, value, day, hour, query)
                    if result:
                        results[indicator] = result  # ä½¿ç”¨åŸå§‹æŒ‡æ ‡åä½œä¸ºé”®
                        dynamic_indicators.append(indicator)
                        if "åŠ¨æ€è¯¦æƒ…" in result:
                            dynamic_details[indicator] = result["åŠ¨æ€è¯¦æƒ…"]
                    else:
                        skipped_indicators.append(f"{indicator} (åŠ¨æ€è¯„ä¼°å¤±è´¥)")
                        
                elif mapped_indicator in self.ratio_indicators:
                    # æ¯”ç‡å‹æŒ‡æ ‡ä½¿ç”¨ä¼ ç»Ÿè¯„ä¼°
                    result = self._traditional_evaluation(mapped_indicator, value, key)
                    if result:
                        results[indicator] = result  # ä½¿ç”¨åŸå§‹æŒ‡æ ‡åä½œä¸ºé”®
                        traditional_indicators.append(indicator)
                    else:
                        skipped_indicators.append(f"{indicator} (ä¼ ç»Ÿè¯„ä¼°å¤±è´¥)")
                else:
                    # æœªåˆ†ç±»çš„æŒ‡æ ‡
                    skipped_indicators.append(f"{indicator} (æœªåœ¨é…ç½®ä¸­åˆ†ç±»)")
            
            # ç»Ÿè®¡è¯„ä¼°ç»“æœ
            total_evaluated = len(dynamic_indicators) + len(traditional_indicators)
            print(f"âœ… æˆåŠŸè¯„ä¼°æŒ‡æ ‡: {total_evaluated}ä¸ª")
            print(f"ğŸ¯ åŠ¨æ€è¯„ä¼°: {len(dynamic_indicators)}ä¸ª")
            print(f"ğŸ“Š ä¼ ç»Ÿè¯„ä¼°: {len(traditional_indicators)}ä¸ª")
            
            if skipped_indicators:
                print(f"âš ï¸ è·³è¿‡æŒ‡æ ‡: {len(skipped_indicators)}ä¸ª")
                for skip_info in skipped_indicators:
                    print(f"   - {skip_info}")
            
            # æ„å»ºæœ€ç»ˆç»“æœ
            diagnosis_result = {
                "è¯Šæ–­æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "æŸ¥è¯¢æ—¶æ®µ": f"æ˜ŸæœŸ{day+1} {hour}:00",
                "è¾“å…¥ç»Ÿè®¡": {
                    "æ€»è¾“å…¥æŒ‡æ ‡": len(input_indicators),
                    "æˆåŠŸè¯„ä¼°": total_evaluated,
                    "è·³è¿‡æ•°é‡": len(skipped_indicators),
                    "è¯„ä¼°æˆåŠŸç‡": f"{(total_evaluated/len(input_indicators)*100):.1f}%" if input_indicators else "0%"
                },
                "æŒ‡æ ‡åˆ†ç±»": {
                    "åŠ¨æ€è¯„ä¼°æŒ‡æ ‡": dynamic_indicators,
                    "ä¼ ç»Ÿè¯„ä¼°æŒ‡æ ‡": traditional_indicators,
                    "è·³è¿‡æŒ‡æ ‡": skipped_indicators
                },
                "è¯„ä¼°ç»“æœ": results
            }
            
            if dynamic_details:
                diagnosis_result["åŠ¨æ€è¯„ä¼°è¯¦æƒ…"] = dynamic_details
            
            return diagnosis_result
            
        except Exception as e:
            error_msg = f"è¯Šæ–­å¤±è´¥: {e}"
            self._log_error("ERROR", error_msg, str(e))
            return {"error": error_msg}
    def _dynamic_evaluation(self, indicator: str, value: float, day: int, hour: int, query: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """åŠ¨æ€è¯„ä¼°ç®—æ³•ï¼ˆè€ƒè™‘å¤§ç›˜è¶‹åŠ¿ï¼‰- å¢å¼ºç‰ˆï¼Œæ”¯æŒå›é€€æœºåˆ¶"""
        try:
            # ç®€åŒ–ç‰ˆåŠ¨æ€è¯„ä¼°ï¼šåŸºäºå½“å‰å€¼å’Œæ ‡å‡†è¿›åº¦
            progress_key = f"{day}_{hour}"
            baseline_value = None
            standard_progress = None
            fallback_method = ""
            
            # 1. å°è¯•è·å–ç²¾ç¡®åŒ¹é…çš„åŸºçº¿å€¼
            if progress_key in self.baseline_table and indicator in self.baseline_table[progress_key]:
                baseline_value = self.baseline_table[progress_key][indicator]
                if progress_key in self.standard_progress_table and indicator in self.standard_progress_table[progress_key]:
                    standard_progress = self.standard_progress_table[progress_key][indicator]
                fallback_method = "ç²¾ç¡®åŒ¹é…"
            
            # 2. å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œå°è¯•åŒä¸€å°æ—¶çš„å…¶ä»–å¤©
            if baseline_value is None:
                for test_day in range(7):
                    test_key = f"{test_day}_{hour}"
                    if test_key in self.baseline_table and indicator in self.baseline_table[test_key]:
                        baseline_value = self.baseline_table[test_key][indicator]
                        if test_key in self.standard_progress_table and indicator in self.standard_progress_table[test_key]:
                            standard_progress = self.standard_progress_table[test_key][indicator]
                        fallback_method = f"åŒæ—¶æ®µå›é€€(æ˜ŸæœŸ{test_day+1})"
                        break
            
            # 3. å¦‚æœè¿˜æ²¡æœ‰ï¼Œå°è¯•åŒä¸€å¤©çš„å…¶ä»–å°æ—¶
            if baseline_value is None:
                for test_hour in range(24):
                    test_key = f"{day}_{test_hour}"
                    if test_key in self.baseline_table and indicator in self.baseline_table[test_key]:
                        baseline_value = self.baseline_table[test_key][indicator]
                        if test_key in self.standard_progress_table and indicator in self.standard_progress_table[test_key]:
                            standard_progress = self.standard_progress_table[test_key][indicator]
                        fallback_method = f"åŒæ—¥å›é€€({test_hour}:00)"
                        break
            
            # 4. æœ€åå°è¯•å…¨å±€å¹³å‡å€¼
            if baseline_value is None:
                all_values = []
                for key, indicators in self.baseline_table.items():
                    if indicator in indicators and indicators[indicator] > 0:
                        all_values.append(indicators[indicator])
                if all_values:
                    baseline_value = sum(all_values) / len(all_values)
                    standard_progress = 0.5  # é»˜è®¤è¿›åº¦
                    fallback_method = f"å…¨å±€å¹³å‡({len(all_values)}ä¸ªæ ·æœ¬)"
            
            # è°ƒè¯•ä¿¡æ¯ï¼šè¾“å‡ºåŸºçº¿å€¼æå–è¿‡ç¨‹
            print(f"ğŸ” åŠ¨æ€è¯„ä¼°è°ƒè¯• - æŒ‡æ ‡: {indicator}, åŸºçº¿å€¼: {baseline_value}, å›é€€æ–¹æ³•: {fallback_method}")
            
            # å¦‚æœæ‰¾åˆ°äº†åŸºçº¿å€¼ï¼Œè¿›è¡Œè¯„ä¼°
            if baseline_value is not None and baseline_value > 0:
                # åŠ¨æ€ç³»æ•°è®¡ç®—
                dynamic_coefficient = value / baseline_value
                
                # è¯„ä¼°ç»“æœ
                if dynamic_coefficient >= 1.5:
                    level = "ä¼˜ç§€"
                elif dynamic_coefficient >= 1.2:
                    level = "è‰¯å¥½"
                elif dynamic_coefficient >= 0.8:
                    level = "æ­£å¸¸"
                else:
                    level = "éœ€æ”¹è¿›"
                
                return {
                    "ç³»æ•°": round(dynamic_coefficient, 2),
                    "è¯„ä¼°": level,
                    "è¯„ä¼°æ–¹æ³•": f"åŠ¨æ€è¯„ä¼°({fallback_method})",
                    "åŠ¨æ€è¯¦æƒ…": {
                        "æ ‡å‡†è¿›åº¦": f"{(standard_progress or 0.5)*100:.1f}%",
                        "åŸºçº¿å€¼": f"{baseline_value:.0f}",
                        "å®é™…å€¼": f"{value:.0f}",
                        "å›é€€æ–¹æ³•": fallback_method
                    }
                }
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŸºçº¿å€¼ï¼Œä½†æŒ‡æ ‡å€¼æœ‰æ•ˆï¼Œæä¾›åŸºç¡€è¯„ä¼°
            if value > 0:
                return {
                    "ç³»æ•°": 1.0,
                    "è¯„ä¼°": "æ•°æ®ä¸è¶³",
                    "è¯„ä¼°æ–¹æ³•": "åŸºç¡€è¯„ä¼°(æ— åŸºçº¿æ•°æ®)",
                    "åŠ¨æ€è¯¦æƒ…": {
                        "æ ‡å‡†è¿›åº¦": "50.0%",
                        "åŸºçº¿å€¼": "æ— ",
                        "å®é™…å€¼": f"{value:.0f}",
                        "å›é€€æ–¹æ³•": "æ— åŸºçº¿æ•°æ®"
                    }
                }
            
            return None
            
        except Exception as e:
            self._log_error("ERROR", f"åŠ¨æ€è¯„ä¼°å¤±è´¥ - {indicator}", str(e))
            return None
    
    def _traditional_evaluation(self, indicator: str, value: float, key: str) -> Optional[Dict[str, Any]]:
        """ä¼ ç»Ÿè¯„ä¼°ç®—æ³• - å¢å¼ºç‰ˆï¼Œæ”¯æŒå›é€€æœºåˆ¶"""
        try:
            baseline_value = None
            fallback_method = ""
            day, hour = key.split('_')
            day, hour = int(day), int(hour)
            
            # 1. å°è¯•è·å–ç²¾ç¡®åŒ¹é…çš„åŸºçº¿å€¼
            if key in self.baseline_table and indicator in self.baseline_table[key]:
                baseline_value = self.baseline_table[key][indicator]
                fallback_method = "ç²¾ç¡®åŒ¹é…"
            
            # 2. å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œå°è¯•åŒä¸€å°æ—¶çš„å…¶ä»–å¤©
            if baseline_value is None or baseline_value <= 0:
                for test_day in range(7):
                    test_key = f"{test_day}_{hour}"
                    if test_key in self.baseline_table and indicator in self.baseline_table[test_key]:
                        test_value = self.baseline_table[test_key][indicator]
                        if test_value > 0:
                            baseline_value = test_value
                            fallback_method = f"åŒæ—¶æ®µå›é€€(æ˜ŸæœŸ{test_day+1})"
                            break
            
            # 3. å¦‚æœè¿˜æ²¡æœ‰ï¼Œå°è¯•åŒä¸€å¤©çš„å…¶ä»–å°æ—¶
            if baseline_value is None or baseline_value <= 0:
                for test_hour in range(24):
                    test_key = f"{day}_{test_hour}"
                    if test_key in self.baseline_table and indicator in self.baseline_table[test_key]:
                        test_value = self.baseline_table[test_key][indicator]
                        if test_value > 0:
                            baseline_value = test_value
                            fallback_method = f"åŒæ—¥å›é€€({test_hour}:00)"
                            break
            
            # 4. æœ€åå°è¯•å…¨å±€å¹³å‡å€¼
            if baseline_value is None or baseline_value <= 0:
                all_values = []
                for test_key, indicators in self.baseline_table.items():
                    if indicator in indicators and indicators[indicator] > 0:
                        all_values.append(indicators[indicator])
                if all_values:
                    baseline_value = sum(all_values) / len(all_values)
                    fallback_method = f"å…¨å±€å¹³å‡({len(all_values)}ä¸ªæ ·æœ¬)"
                elif indicator in self.ratio_indicators:
                    # å¯¹äºæ¯”ç‡å‹æŒ‡æ ‡ï¼Œä½¿ç”¨é»˜è®¤å€¼1.0
                    baseline_value = 1.0
                    fallback_method = "é»˜è®¤åŸºçº¿å€¼"
            
            # è°ƒè¯•ä¿¡æ¯ï¼šè¾“å‡ºä¼ ç»Ÿè¯„ä¼°çš„åŸºçº¿å€¼æå–ç»“æœ
            print(f"ğŸ” ä¼ ç»Ÿè¯„ä¼°è°ƒè¯• - æŒ‡æ ‡: {indicator}, åŸºçº¿å€¼: {baseline_value}, å›é€€æ–¹æ³•: {fallback_method}")
            
            # å¦‚æœæ‰¾åˆ°äº†æœ‰æ•ˆçš„åŸºçº¿å€¼ï¼Œè¿›è¡Œè¯„ä¼°
            if baseline_value is not None and baseline_value > 0:
                try:
                    value = float(value)
                    baseline_value = float(baseline_value)
                    coefficient = value / baseline_value
                    
                    # è¯„ä¼°ç»“æœ
                    if coefficient >= 1.2:
                        level = "ä¼˜ç§€"
                    elif coefficient >= 1.1:
                        level = "è‰¯å¥½"
                    elif coefficient >= 0.9:
                        level = "æ­£å¸¸"
                    else:
                        level = "éœ€æ”¹è¿›"
                    
                    return {
                        "ç³»æ•°": round(coefficient, 2),
                        "è¯„ä¼°": level,
                        "è¯„ä¼°æ–¹æ³•": f"ä¼ ç»Ÿè¯„ä¼°({fallback_method})",
                        "åŸºçº¿å€¼": round(baseline_value, 2)
                    }
                except Exception as e:
                    print(f"  - è®¡ç®—{indicator}ç³»æ•°æ—¶å‡ºé”™: {e}")
                    return None
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŸºçº¿å€¼ï¼Œä½†æŒ‡æ ‡å€¼æœ‰æ•ˆï¼Œæä¾›åŸºç¡€è¯„ä¼°
            if value > 0:
                return {
                    "ç³»æ•°": 1.0,
                    "è¯„ä¼°": "æ•°æ®ä¸è¶³",
                    "è¯„ä¼°æ–¹æ³•": "åŸºç¡€è¯„ä¼°(æ— åŸºçº¿æ•°æ®)",
                    "åŸºçº¿å€¼": "æ— "
                }
            
            return None
            
        except Exception as e:
            self._log_error("ERROR", f"ä¼ ç»Ÿè¯„ä¼°å¤±è´¥ - {indicator}", str(e))
            return None
    
    def export_baseline_snapshot(self) -> str:
        """å¯¼å‡ºåŸºçº¿å¿«ç…§"""
        try:
            if not self.is_initialized:
                return "ç³»ç»Ÿæœªåˆå§‹åŒ–"
            
            # åˆ›å»ºå¯¼å‡ºç›®å½•
            export_dir = os.path.join(self.data_dir, "åŸºçº¿å¿«ç…§")
            os.makedirs(export_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # å¯¼å‡ºåŸºçº¿æ•°æ®ä¸ºCSV
            baseline_data = []
            for key, values in self.baseline_table.items():
                day, hour = key.split('_')
                for indicator, baseline_value in values.items():
                    eval_method = "åŠ¨æ€è¯„ä¼°" if indicator in self.absolute_indicators else "ä¼ ç»Ÿè¯„ä¼°"
                    baseline_data.append({
                        "æ˜ŸæœŸå‡ ": int(day),
                        "å°æ—¶": int(hour),
                        "æŒ‡æ ‡": indicator,
                        "åŸºçº¿å€¼": baseline_value,
                        "è¯„ä¼°æ–¹æ³•": eval_method
                    })
            
            baseline_df = pd.DataFrame(baseline_data)
            baseline_csv = os.path.join(export_dir, f"baseline_data_real_{timestamp}.csv")
            baseline_df.to_csv(baseline_csv, index=False, encoding='utf-8')
            
            # å¯¼å‡ºå®Œæ•´é…ç½®ä¸ºJSON
            export_data = {
                "å¯¼å‡ºæ—¶é—´": datetime.now().isoformat(),
                "æ•°æ®æ± å¤§å°": len(self.data_pool),
                "åŸºçº¿è¦†ç›–æ—¶æ®µ": len(self.baseline_table),
                "æ ‡å‡†è¿›åº¦è¡¨æ—¶æ®µ": len(self.standard_progress_table),
                "ç»å¯¹æ•°å€¼å‹æŒ‡æ ‡": list(self.absolute_indicators),
                "æ¯”ç‡å‹æŒ‡æ ‡": list(self.ratio_indicators),
                "åŸºçº¿è¡¨": self.baseline_table,
                "æ ‡å‡†è¿›åº¦è¡¨": self.standard_progress_table
            }
            
            json_file = os.path.join(export_dir, f"baseline_snapshot_real_{timestamp}.json")
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… åŸºçº¿å¿«ç…§å¯¼å‡ºå®Œæˆ:")
            print(f"ğŸ“„ CSVæ–‡ä»¶: {baseline_csv}")
            print(f"ğŸ“„ JSONæ–‡ä»¶: {json_file}")
            
            return json_file
            
        except Exception as e:
            error_msg = f"å¯¼å‡ºå¤±è´¥: {e}"
            self._log_error("ERROR", error_msg, str(e))
            return error_msg
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        try:
            return {
                "ç³»ç»ŸçŠ¶æ€": "å·²åˆå§‹åŒ–" if self.is_initialized else "æœªåˆå§‹åŒ–",
                "æ•°æ®æ± å¤§å°": len(self.data_pool),
                "åŸºçº¿è¦†ç›–æ—¶æ®µ": len(self.baseline_table),
                "æ ‡å‡†è¿›åº¦è¡¨æ—¶æ®µ": len(self.standard_progress_table),
                "æ”¯æŒæŒ‡æ ‡": {
                    "ç»å¯¹æ•°å€¼å‹": len(self.absolute_indicators),
                    "æ¯”ç‡å‹": len(self.ratio_indicators),
                    "æ€»è®¡": len(self.absolute_indicators) + len(self.ratio_indicators)
                },
                "æœ€åæ›´æ–°": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        except Exception as e:
            return {"error": f"è·å–çŠ¶æ€å¤±è´¥: {e}"}

# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    system = RealDataDynamicBaseline()
    
    # ä½¿ç”¨çœŸå®å†å²æ•°æ®åˆå§‹åŒ–
    historical_data = "/workspace/data/old_table_real.csv"
    if system.initialize_system(historical_data):
        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        
        # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
        status = system.get_system_status()
        print(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€: {status}")
    else:
        print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
    